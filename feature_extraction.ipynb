{
 "cells": [
  {
   "cell_type": "code",
   "id": "1d1d7e68fcd0259d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T15:37:57.647285Z",
     "start_time": "2025-11-28T15:37:57.644603Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import polars as pl"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "7fe86664a598b6a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T15:37:57.669270Z",
     "start_time": "2025-11-28T15:37:57.653662Z"
    }
   },
   "source": [
    "SEED = 462\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "DESCRIPTION_WORDS_COUNT = 2\n",
    "GRAYSCALE_SIZE = (8, 8)"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "b5e5e5c92672ee99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T15:37:57.699299Z",
     "start_time": "2025-11-28T15:37:57.697707Z"
    }
   },
   "source": [
    "data_path = \"data\"\n",
    "image_data_path = os.path.join(data_path, \"image\")\n",
    "vocabulary_path = os.path.join(data_path, \"vocabulary.json\")\n",
    "dataset_splits = [\"train\", \"validation\", \"test\"]"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T15:37:57.751575Z",
     "start_time": "2025-11-28T15:37:57.748088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FEATURES = {\n",
    "    \"image\": True,\n",
    "    \"numeric\": True,\n",
    "    \"categorical\": True\n",
    "}"
   ],
   "id": "71c9b05b231f6161",
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "194462675308a558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T15:37:57.797674Z",
     "start_time": "2025-11-28T15:37:57.795679Z"
    }
   },
   "source": [
    "def enumerate_dataset(dataset_path):\n",
    "    return {\n",
    "        cls: os.listdir(os.path.join(dataset_path, cls))\n",
    "        for cls in os.listdir(dataset_path)\n",
    "        if os.path.isdir(os.path.join(dataset_path, cls))\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "585df0f4cef59e36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T15:37:57.850899Z",
     "start_time": "2025-11-28T15:37:57.844387Z"
    }
   },
   "source": [
    "datasets = {dataset: enumerate_dataset(os.path.join(image_data_path, dataset)) for dataset in dataset_splits}"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "6edde39c4eb76928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T15:37:57.898768Z",
     "start_time": "2025-11-28T15:37:57.894465Z"
    }
   },
   "source": [
    "feature_words = {\n",
    "    \"banana\": [\"yellow\", \"tropical\", \"long\", \"sweet\", \"soft\", \"peel\"],\n",
    "    \"carrot\": [\"orange\", \"temperate\", \"long\", \"sweet\", \"crunchy\", \"skin\"],\n",
    "    \"cucumber\": [\"green\", \"temperate\", \"long\", \"bland\", \"crunchy\", \"seeds\"],\n",
    "    \"mandarin\": [\n",
    "        \"orange\",\n",
    "        \"tropical\",\n",
    "        \"spherical\",\n",
    "        \"sweet\",\n",
    "        \"sour\",\n",
    "        \"soft\",\n",
    "        \"peel\",\n",
    "    ],\n",
    "    \"tomato\": [\"red\", \"warm\", \"spherical\", \"savory\", \"sour\", \"soft\", \"seeds\"],\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "bf9eb068c088f268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T15:37:57.947753Z",
     "start_time": "2025-11-28T15:37:57.945260Z"
    }
   },
   "source": [
    "vocabulary = set()\n",
    "for words in feature_words.values():\n",
    "    for word in words:\n",
    "        vocabulary.add(word)\n",
    "vocabulary = sorted(vocabulary)\n",
    "with open(vocabulary_path, \"w\") as fp:\n",
    "    json.dump(vocabulary, fp)"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "efa9ef977bafcf63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T15:37:57.992736Z",
     "start_time": "2025-11-28T15:37:57.990902Z"
    }
   },
   "source": [
    "# grams(mean, std), cm(mean, std)\n",
    "dist_params = {\n",
    "    \"banana\": {\"weight\": (120, 16), \"size\": (18, 2.5)},\n",
    "    \"carrot\": {\"weight\": (60, 11), \"size\": (15, 3)},\n",
    "    \"cucumber\": {\"weight\": (300, 42), \"size\": (20, 3.5)},\n",
    "    \"mandarin\": {\"weight\": (80, 13), \"size\": (6.5, 1)},\n",
    "    \"tomato\": {\"weight\": (100, 16), \"size\": (7, 1.2)},\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "369bafddda79c3cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T15:37:58.040483Z",
     "start_time": "2025-11-28T15:37:58.037700Z"
    }
   },
   "source": [
    "def extract_features(image, image_class):\n",
    "    features = {}\n",
    "\n",
    "    if FEATURES[\"image\"]:\n",
    "        small = cv2.resize(image, GRAYSCALE_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        gray_small = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)\n",
    "        gray_flat = gray_small.reshape(-1).astype(\"float32\")\n",
    "        for i, val in enumerate(gray_flat):\n",
    "            features[f\"gray_{i:03d}\"] = float(val)  # type: ignore | here we know gray_flat is 1d array\n",
    "\n",
    "        blue = image[:, :, 0]\n",
    "        green = image[:, :, 1]\n",
    "        red = image[:, :, 2]\n",
    "\n",
    "        features[\"blue_mean\"] = float(np.mean(blue))\n",
    "        features[\"blue_std\"] = float(np.std(blue))\n",
    "        features[\"green_mean\"] = float(np.mean(green))\n",
    "        features[\"green_std\"] = float(np.std(green))\n",
    "        features[\"red_mean\"] = float(np.mean(red))\n",
    "        features[\"red_std\"] = float(np.std(red))\n",
    "\n",
    "    if FEATURES[\"numeric\"]:\n",
    "        params = dist_params[image_class]\n",
    "        features[\"weight\"] = float(np.random.normal(*params[\"weight\"]))\n",
    "        features[\"size\"] = float(np.random.normal(*params[\"size\"]))\n",
    "\n",
    "    if FEATURES[\"categorical\"]:\n",
    "        features[\"description\"] = \" \".join(random.sample(feature_words[image_class], DESCRIPTION_WORDS_COUNT))\n",
    "\n",
    "    features[\"class\"] = image_class\n",
    "    return features"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "96e7a3399b05f435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T15:38:33.666765Z",
     "start_time": "2025-11-28T15:37:58.086911Z"
    }
   },
   "source": [
    "tabular_path = os.path.join(data_path, \"tabular\")\n",
    "os.makedirs(tabular_path, exist_ok=True)\n",
    "for split, dataset in datasets.items():\n",
    "    destination_path = os.path.join(tabular_path, f\"{split}.csv\")\n",
    "    rows = []\n",
    "    for class_, images in dataset.items():\n",
    "        for image in images:\n",
    "            image_path = os.path.join(image_data_path, split, class_, image)\n",
    "            rows.append(extract_features(cv2.imread(image_path), class_))\n",
    "    df = pl.DataFrame(rows)\n",
    "    df.write_csv(destination_path)"
   ],
   "outputs": [],
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "0f880a9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:48:13.181984Z",
     "start_time": "2025-11-28T11:48:13.180428Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:48:13.214189Z",
     "start_time": "2025-11-28T11:48:13.185102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED=462\n",
    "np.random.seed(SEED)"
   ],
   "id": "ac77e339a8b46e1e",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:48:13.237766Z",
     "start_time": "2025-11-28T11:48:13.233136Z"
    }
   },
   "cell_type": "code",
   "source": "data_path = os.path.join(\"data\", \"tabular\")",
   "id": "5240eb93449fa9bc",
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "id": "9a21560b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:48:13.290294Z",
     "start_time": "2025-11-28T11:48:13.282838Z"
    }
   },
   "source": [
    "class Dataset:\n",
    "    def __init__(self, train_path, val_path, test_path):\n",
    "        self.train_path = train_path\n",
    "        self.val_path = val_path\n",
    "        self.test_path = test_path\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.label_map = None\n",
    "\n",
    "    def load_csv(self, path):\n",
    "        df = pl.read_csv(path)\n",
    "        data = df.to_numpy()\n",
    "        X = data[:, :-1].astype(float)\n",
    "        Y_str = data[:, -1]\n",
    "        return X, Y_str\n",
    "\n",
    "    def encode_labels(self, Y_str, fit=False):\n",
    "        if fit:\n",
    "            unique_labels = np.unique(Y_str)\n",
    "            self.label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "        Y = np.array([self.label_map[label] for label in Y_str])\n",
    "        return Y\n",
    "\n",
    "    def normalize(self, X, fit=False):\n",
    "        if fit:\n",
    "            self.mean = np.mean(X, axis=0)\n",
    "            self.std = np.std(X, axis=0)\n",
    "            self.std[self.std == 0] = 1.0\n",
    "\n",
    "        return (X - self.mean) / self.std\n",
    "\n",
    "    def get_data(self):\n",
    "        X_train, Y_train_str = self.load_csv(self.train_path)\n",
    "        X_val, Y_val_str = self.load_csv(self.val_path)\n",
    "        X_test, Y_test_str = self.load_csv(self.test_path)\n",
    "\n",
    "        Y_train = self.encode_labels(Y_train_str, fit=True)\n",
    "        Y_val = self.encode_labels(Y_val_str, fit=False)\n",
    "        Y_test = self.encode_labels(Y_test_str, fit=False)\n",
    "\n",
    "        X_train = self.normalize(X_train, fit=True)\n",
    "        X_val = self.normalize(X_val, fit=False)\n",
    "        X_test = self.normalize(X_test, fit=False)\n",
    "\n",
    "        return (X_train, Y_train), (X_val, Y_val), (X_test, Y_test)"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "id": "9d437f66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:48:13.335283Z",
     "start_time": "2025-11-28T11:48:13.332656Z"
    }
   },
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate, num_iters):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iters = num_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.sigmoid(np.dot(X, self.weights) + self.bias)\n",
    "\n",
    "    def logistic_loss(self, y_true, y_pred):\n",
    "        eps = 1e-15\n",
    "        y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        n_examples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for i in range(self.num_iters):\n",
    "            y_pred = self.predict_proba(X)\n",
    "            y_diff = y_pred - Y\n",
    "\n",
    "            self.weights -= self.learning_rate * np.dot(X.T, y_diff) / n_examples\n",
    "            self.bias -= self.learning_rate * np.mean(y_diff)\n"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "id": "5ad20652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:48:13.387337Z",
     "start_time": "2025-11-28T11:48:13.380462Z"
    }
   },
   "source": [
    "class LogisticRegressionOVA:\n",
    "    def __init__(self, learning_rate=0.01, num_iters=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iters = num_iters\n",
    "        self.models = []\n",
    "        self.classes = None\n",
    "\n",
    "    def train(self, X_train, Y_train, X_val, Y_val):\n",
    "        self.classes = np.unique(Y_train)\n",
    "        self.models = []\n",
    "\n",
    "        for cls in self.classes:\n",
    "            print(f\"Training for class {cls}...\")\n",
    "            Y_train_bin = (Y_train == cls).astype(float)\n",
    "            Y_val_bin = (Y_val == cls).astype(float)\n",
    "\n",
    "            model = LogisticRegression(self.learning_rate, self.num_iters)\n",
    "\n",
    "            # Custom training loop to print loss\n",
    "            n_examples, n_features = X_train.shape\n",
    "            model.weights = np.zeros(n_features)\n",
    "            model.bias = 0\n",
    "\n",
    "            for i in range(model.num_iters):\n",
    "                y_pred = model.predict_proba(X_train)\n",
    "                y_diff = y_pred - Y_train_bin\n",
    "\n",
    "                model.weights -= model.learning_rate * np.dot(X_train.T, y_diff) / n_examples\n",
    "                model.bias -= model.learning_rate * np.mean(y_diff)\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    train_loss = model.logistic_loss(Y_train_bin, y_pred)\n",
    "                    val_pred = model.predict_proba(X_val)\n",
    "                    val_loss = model.logistic_loss(Y_val_bin, val_pred)\n",
    "                    print(f\"Iter {i}: Train Loss {train_loss:.4f}, Val Loss {val_loss:.4f}\")\n",
    "\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = np.column_stack([model.predict_proba(X) for model in self.models])\n",
    "        return np.argmax(probs, axis=1)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred) * 100\n"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "id": "76d20260",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:48:13.432864Z",
     "start_time": "2025-11-28T11:48:13.430548Z"
    }
   },
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred) * 100"
   ],
   "outputs": [],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "id": "f4383e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T11:48:53.070973Z",
     "start_time": "2025-11-28T11:48:13.479406Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = Dataset(\n",
    "        train_path=os.path.join(data_path, \"train_processed.csv\"),\n",
    "        val_path=os.path.join(data_path, \"validation_processed.csv\"),\n",
    "        test_path=os.path.join(data_path, \"test_processed.csv\"),\n",
    "    )\n",
    "\n",
    "    (X_train, Y_train), (X_val, Y_val), (X_test, Y_test) = dataset.get_data()\n",
    "\n",
    "    model = LogisticRegressionOVA(learning_rate=0.001, num_iters=50000)\n",
    "    model.train(X_train, Y_train, X_val, Y_val)\n",
    "\n",
    "    test_pred = model.predict(X_test)\n",
    "    print(f\"Test Accuracy: {accuracy(Y_test, test_pred):.2f}%\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for class 0...\n",
      "Iter 0: Train Loss 0.6931, Val Loss 0.6926\n",
      "Iter 1000: Train Loss 0.4619, Val Loss 0.4689\n",
      "Iter 2000: Train Loss 0.3690, Val Loss 0.3752\n",
      "Iter 3000: Train Loss 0.3108, Val Loss 0.3164\n",
      "Iter 4000: Train Loss 0.2705, Val Loss 0.2757\n",
      "Iter 5000: Train Loss 0.2408, Val Loss 0.2459\n",
      "Iter 6000: Train Loss 0.2182, Val Loss 0.2231\n",
      "Iter 7000: Train Loss 0.2003, Val Loss 0.2052\n",
      "Iter 8000: Train Loss 0.1858, Val Loss 0.1906\n",
      "Iter 9000: Train Loss 0.1738, Val Loss 0.1787\n",
      "Iter 10000: Train Loss 0.1637, Val Loss 0.1686\n",
      "Iter 11000: Train Loss 0.1550, Val Loss 0.1599\n",
      "Iter 12000: Train Loss 0.1475, Val Loss 0.1525\n",
      "Iter 13000: Train Loss 0.1409, Val Loss 0.1460\n",
      "Iter 14000: Train Loss 0.1351, Val Loss 0.1402\n",
      "Iter 15000: Train Loss 0.1299, Val Loss 0.1351\n",
      "Iter 16000: Train Loss 0.1253, Val Loss 0.1305\n",
      "Iter 17000: Train Loss 0.1211, Val Loss 0.1263\n",
      "Iter 18000: Train Loss 0.1173, Val Loss 0.1225\n",
      "Iter 19000: Train Loss 0.1138, Val Loss 0.1191\n",
      "Iter 20000: Train Loss 0.1105, Val Loss 0.1159\n",
      "Iter 21000: Train Loss 0.1076, Val Loss 0.1130\n",
      "Iter 22000: Train Loss 0.1048, Val Loss 0.1103\n",
      "Iter 23000: Train Loss 0.1023, Val Loss 0.1078\n",
      "Iter 24000: Train Loss 0.0999, Val Loss 0.1054\n",
      "Iter 25000: Train Loss 0.0977, Val Loss 0.1033\n",
      "Iter 26000: Train Loss 0.0956, Val Loss 0.1012\n",
      "Iter 27000: Train Loss 0.0937, Val Loss 0.0993\n",
      "Iter 28000: Train Loss 0.0918, Val Loss 0.0975\n",
      "Iter 29000: Train Loss 0.0901, Val Loss 0.0958\n",
      "Iter 30000: Train Loss 0.0885, Val Loss 0.0942\n",
      "Iter 31000: Train Loss 0.0869, Val Loss 0.0926\n",
      "Iter 32000: Train Loss 0.0854, Val Loss 0.0912\n",
      "Iter 33000: Train Loss 0.0840, Val Loss 0.0898\n",
      "Iter 34000: Train Loss 0.0827, Val Loss 0.0885\n",
      "Iter 35000: Train Loss 0.0814, Val Loss 0.0872\n",
      "Iter 36000: Train Loss 0.0802, Val Loss 0.0861\n",
      "Iter 37000: Train Loss 0.0790, Val Loss 0.0849\n",
      "Iter 38000: Train Loss 0.0779, Val Loss 0.0838\n",
      "Iter 39000: Train Loss 0.0768, Val Loss 0.0828\n",
      "Iter 40000: Train Loss 0.0758, Val Loss 0.0818\n",
      "Iter 41000: Train Loss 0.0748, Val Loss 0.0808\n",
      "Iter 42000: Train Loss 0.0739, Val Loss 0.0799\n",
      "Iter 43000: Train Loss 0.0730, Val Loss 0.0790\n",
      "Iter 44000: Train Loss 0.0721, Val Loss 0.0781\n",
      "Iter 45000: Train Loss 0.0713, Val Loss 0.0773\n",
      "Iter 46000: Train Loss 0.0705, Val Loss 0.0765\n",
      "Iter 47000: Train Loss 0.0697, Val Loss 0.0757\n",
      "Iter 48000: Train Loss 0.0689, Val Loss 0.0750\n",
      "Iter 49000: Train Loss 0.0682, Val Loss 0.0743\n",
      "Training for class 1...\n",
      "Iter 0: Train Loss 0.6931, Val Loss 0.6928\n",
      "Iter 1000: Train Loss 0.4802, Val Loss 0.4832\n",
      "Iter 2000: Train Loss 0.3724, Val Loss 0.3766\n",
      "Iter 3000: Train Loss 0.3073, Val Loss 0.3121\n",
      "Iter 4000: Train Loss 0.2639, Val Loss 0.2689\n",
      "Iter 5000: Train Loss 0.2327, Val Loss 0.2378\n",
      "Iter 6000: Train Loss 0.2092, Val Loss 0.2143\n",
      "Iter 7000: Train Loss 0.1908, Val Loss 0.1959\n",
      "Iter 8000: Train Loss 0.1760, Val Loss 0.1810\n",
      "Iter 9000: Train Loss 0.1638, Val Loss 0.1687\n",
      "Iter 10000: Train Loss 0.1535, Val Loss 0.1583\n",
      "Iter 11000: Train Loss 0.1447, Val Loss 0.1495\n",
      "Iter 12000: Train Loss 0.1371, Val Loss 0.1418\n",
      "Iter 13000: Train Loss 0.1304, Val Loss 0.1351\n",
      "Iter 14000: Train Loss 0.1246, Val Loss 0.1291\n",
      "Iter 15000: Train Loss 0.1193, Val Loss 0.1238\n",
      "Iter 16000: Train Loss 0.1146, Val Loss 0.1190\n",
      "Iter 17000: Train Loss 0.1104, Val Loss 0.1147\n",
      "Iter 18000: Train Loss 0.1065, Val Loss 0.1107\n",
      "Iter 19000: Train Loss 0.1030, Val Loss 0.1071\n",
      "Iter 20000: Train Loss 0.0998, Val Loss 0.1038\n",
      "Iter 21000: Train Loss 0.0968, Val Loss 0.1008\n",
      "Iter 22000: Train Loss 0.0940, Val Loss 0.0980\n",
      "Iter 23000: Train Loss 0.0915, Val Loss 0.0954\n",
      "Iter 24000: Train Loss 0.0891, Val Loss 0.0929\n",
      "Iter 25000: Train Loss 0.0869, Val Loss 0.0907\n",
      "Iter 26000: Train Loss 0.0848, Val Loss 0.0885\n",
      "Iter 27000: Train Loss 0.0829, Val Loss 0.0865\n",
      "Iter 28000: Train Loss 0.0810, Val Loss 0.0846\n",
      "Iter 29000: Train Loss 0.0793, Val Loss 0.0829\n",
      "Iter 30000: Train Loss 0.0777, Val Loss 0.0812\n",
      "Iter 31000: Train Loss 0.0761, Val Loss 0.0796\n",
      "Iter 32000: Train Loss 0.0746, Val Loss 0.0781\n",
      "Iter 33000: Train Loss 0.0733, Val Loss 0.0766\n",
      "Iter 34000: Train Loss 0.0719, Val Loss 0.0753\n",
      "Iter 35000: Train Loss 0.0707, Val Loss 0.0740\n",
      "Iter 36000: Train Loss 0.0695, Val Loss 0.0727\n",
      "Iter 37000: Train Loss 0.0683, Val Loss 0.0716\n",
      "Iter 38000: Train Loss 0.0672, Val Loss 0.0704\n",
      "Iter 39000: Train Loss 0.0662, Val Loss 0.0693\n",
      "Iter 40000: Train Loss 0.0652, Val Loss 0.0683\n",
      "Iter 41000: Train Loss 0.0642, Val Loss 0.0673\n",
      "Iter 42000: Train Loss 0.0633, Val Loss 0.0664\n",
      "Iter 43000: Train Loss 0.0624, Val Loss 0.0654\n",
      "Iter 44000: Train Loss 0.0615, Val Loss 0.0645\n",
      "Iter 45000: Train Loss 0.0607, Val Loss 0.0637\n",
      "Iter 46000: Train Loss 0.0599, Val Loss 0.0629\n",
      "Iter 47000: Train Loss 0.0591, Val Loss 0.0621\n",
      "Iter 48000: Train Loss 0.0584, Val Loss 0.0613\n",
      "Iter 49000: Train Loss 0.0577, Val Loss 0.0606\n",
      "Training for class 2...\n",
      "Iter 0: Train Loss 0.6931, Val Loss 0.6925\n",
      "Iter 1000: Train Loss 0.3924, Val Loss 0.4015\n",
      "Iter 2000: Train Loss 0.2808, Val Loss 0.2911\n",
      "Iter 3000: Train Loss 0.2191, Val Loss 0.2292\n",
      "Iter 4000: Train Loss 0.1796, Val Loss 0.1892\n",
      "Iter 5000: Train Loss 0.1521, Val Loss 0.1611\n",
      "Iter 6000: Train Loss 0.1318, Val Loss 0.1404\n",
      "Iter 7000: Train Loss 0.1163, Val Loss 0.1244\n",
      "Iter 8000: Train Loss 0.1040, Val Loss 0.1118\n",
      "Iter 9000: Train Loss 0.0941, Val Loss 0.1015\n",
      "Iter 10000: Train Loss 0.0859, Val Loss 0.0931\n",
      "Iter 11000: Train Loss 0.0791, Val Loss 0.0859\n",
      "Iter 12000: Train Loss 0.0732, Val Loss 0.0798\n",
      "Iter 13000: Train Loss 0.0682, Val Loss 0.0746\n",
      "Iter 14000: Train Loss 0.0639, Val Loss 0.0700\n",
      "Iter 15000: Train Loss 0.0600, Val Loss 0.0660\n",
      "Iter 16000: Train Loss 0.0566, Val Loss 0.0625\n",
      "Iter 17000: Train Loss 0.0536, Val Loss 0.0593\n",
      "Iter 18000: Train Loss 0.0509, Val Loss 0.0564\n",
      "Iter 19000: Train Loss 0.0485, Val Loss 0.0539\n",
      "Iter 20000: Train Loss 0.0463, Val Loss 0.0516\n",
      "Iter 21000: Train Loss 0.0443, Val Loss 0.0494\n",
      "Iter 22000: Train Loss 0.0424, Val Loss 0.0475\n",
      "Iter 23000: Train Loss 0.0407, Val Loss 0.0457\n",
      "Iter 24000: Train Loss 0.0392, Val Loss 0.0441\n",
      "Iter 25000: Train Loss 0.0378, Val Loss 0.0426\n",
      "Iter 26000: Train Loss 0.0364, Val Loss 0.0411\n",
      "Iter 27000: Train Loss 0.0352, Val Loss 0.0398\n",
      "Iter 28000: Train Loss 0.0341, Val Loss 0.0386\n",
      "Iter 29000: Train Loss 0.0330, Val Loss 0.0375\n",
      "Iter 30000: Train Loss 0.0320, Val Loss 0.0364\n",
      "Iter 31000: Train Loss 0.0310, Val Loss 0.0354\n",
      "Iter 32000: Train Loss 0.0301, Val Loss 0.0345\n",
      "Iter 33000: Train Loss 0.0293, Val Loss 0.0336\n",
      "Iter 34000: Train Loss 0.0285, Val Loss 0.0327\n",
      "Iter 35000: Train Loss 0.0278, Val Loss 0.0319\n",
      "Iter 36000: Train Loss 0.0271, Val Loss 0.0312\n",
      "Iter 37000: Train Loss 0.0264, Val Loss 0.0305\n",
      "Iter 38000: Train Loss 0.0258, Val Loss 0.0298\n",
      "Iter 39000: Train Loss 0.0252, Val Loss 0.0291\n",
      "Iter 40000: Train Loss 0.0246, Val Loss 0.0285\n",
      "Iter 41000: Train Loss 0.0240, Val Loss 0.0279\n",
      "Iter 42000: Train Loss 0.0235, Val Loss 0.0274\n",
      "Iter 43000: Train Loss 0.0230, Val Loss 0.0269\n",
      "Iter 44000: Train Loss 0.0225, Val Loss 0.0263\n",
      "Iter 45000: Train Loss 0.0221, Val Loss 0.0259\n",
      "Iter 46000: Train Loss 0.0216, Val Loss 0.0254\n",
      "Iter 47000: Train Loss 0.0212, Val Loss 0.0249\n",
      "Iter 48000: Train Loss 0.0208, Val Loss 0.0245\n",
      "Iter 49000: Train Loss 0.0204, Val Loss 0.0241\n",
      "Training for class 3...\n",
      "Iter 0: Train Loss 0.6931, Val Loss 0.6929\n",
      "Iter 1000: Train Loss 0.5143, Val Loss 0.5108\n",
      "Iter 2000: Train Loss 0.4240, Val Loss 0.4198\n",
      "Iter 3000: Train Loss 0.3660, Val Loss 0.3617\n",
      "Iter 4000: Train Loss 0.3251, Val Loss 0.3209\n",
      "Iter 5000: Train Loss 0.2946, Val Loss 0.2905\n",
      "Iter 6000: Train Loss 0.2709, Val Loss 0.2668\n",
      "Iter 7000: Train Loss 0.2518, Val Loss 0.2478\n",
      "Iter 8000: Train Loss 0.2360, Val Loss 0.2322\n",
      "Iter 9000: Train Loss 0.2228, Val Loss 0.2190\n",
      "Iter 10000: Train Loss 0.2114, Val Loss 0.2077\n",
      "Iter 11000: Train Loss 0.2015, Val Loss 0.1979\n",
      "Iter 12000: Train Loss 0.1929, Val Loss 0.1893\n",
      "Iter 13000: Train Loss 0.1852, Val Loss 0.1817\n",
      "Iter 14000: Train Loss 0.1783, Val Loss 0.1749\n",
      "Iter 15000: Train Loss 0.1721, Val Loss 0.1687\n",
      "Iter 16000: Train Loss 0.1664, Val Loss 0.1631\n",
      "Iter 17000: Train Loss 0.1613, Val Loss 0.1580\n",
      "Iter 18000: Train Loss 0.1565, Val Loss 0.1534\n",
      "Iter 19000: Train Loss 0.1522, Val Loss 0.1490\n",
      "Iter 20000: Train Loss 0.1481, Val Loss 0.1451\n",
      "Iter 21000: Train Loss 0.1444, Val Loss 0.1414\n",
      "Iter 22000: Train Loss 0.1409, Val Loss 0.1379\n",
      "Iter 23000: Train Loss 0.1376, Val Loss 0.1347\n",
      "Iter 24000: Train Loss 0.1346, Val Loss 0.1317\n",
      "Iter 25000: Train Loss 0.1317, Val Loss 0.1288\n",
      "Iter 26000: Train Loss 0.1290, Val Loss 0.1262\n",
      "Iter 27000: Train Loss 0.1264, Val Loss 0.1236\n",
      "Iter 28000: Train Loss 0.1240, Val Loss 0.1212\n",
      "Iter 29000: Train Loss 0.1217, Val Loss 0.1190\n",
      "Iter 30000: Train Loss 0.1195, Val Loss 0.1168\n",
      "Iter 31000: Train Loss 0.1174, Val Loss 0.1148\n",
      "Iter 32000: Train Loss 0.1154, Val Loss 0.1129\n",
      "Iter 33000: Train Loss 0.1136, Val Loss 0.1110\n",
      "Iter 34000: Train Loss 0.1118, Val Loss 0.1092\n",
      "Iter 35000: Train Loss 0.1100, Val Loss 0.1075\n",
      "Iter 36000: Train Loss 0.1084, Val Loss 0.1059\n",
      "Iter 37000: Train Loss 0.1068, Val Loss 0.1044\n",
      "Iter 38000: Train Loss 0.1053, Val Loss 0.1029\n",
      "Iter 39000: Train Loss 0.1038, Val Loss 0.1014\n",
      "Iter 40000: Train Loss 0.1024, Val Loss 0.1001\n",
      "Iter 41000: Train Loss 0.1011, Val Loss 0.0987\n",
      "Iter 42000: Train Loss 0.0998, Val Loss 0.0975\n",
      "Iter 43000: Train Loss 0.0985, Val Loss 0.0962\n",
      "Iter 44000: Train Loss 0.0973, Val Loss 0.0951\n",
      "Iter 45000: Train Loss 0.0961, Val Loss 0.0939\n",
      "Iter 46000: Train Loss 0.0950, Val Loss 0.0928\n",
      "Iter 47000: Train Loss 0.0939, Val Loss 0.0917\n",
      "Iter 48000: Train Loss 0.0929, Val Loss 0.0907\n",
      "Iter 49000: Train Loss 0.0918, Val Loss 0.0897\n",
      "Training for class 4...\n",
      "Iter 0: Train Loss 0.6931, Val Loss 0.6921\n",
      "Iter 1000: Train Loss 0.3735, Val Loss 0.3719\n",
      "Iter 2000: Train Loss 0.2786, Val Loss 0.2778\n",
      "Iter 3000: Train Loss 0.2274, Val Loss 0.2269\n",
      "Iter 4000: Train Loss 0.1943, Val Loss 0.1940\n",
      "Iter 5000: Train Loss 0.1708, Val Loss 0.1706\n",
      "Iter 6000: Train Loss 0.1531, Val Loss 0.1530\n",
      "Iter 7000: Train Loss 0.1393, Val Loss 0.1392\n",
      "Iter 8000: Train Loss 0.1281, Val Loss 0.1281\n",
      "Iter 9000: Train Loss 0.1190, Val Loss 0.1189\n",
      "Iter 10000: Train Loss 0.1113, Val Loss 0.1112\n",
      "Iter 11000: Train Loss 0.1047, Val Loss 0.1046\n",
      "Iter 12000: Train Loss 0.0991, Val Loss 0.0990\n",
      "Iter 13000: Train Loss 0.0941, Val Loss 0.0941\n",
      "Iter 14000: Train Loss 0.0898, Val Loss 0.0897\n",
      "Iter 15000: Train Loss 0.0860, Val Loss 0.0859\n",
      "Iter 16000: Train Loss 0.0826, Val Loss 0.0825\n",
      "Iter 17000: Train Loss 0.0795, Val Loss 0.0794\n",
      "Iter 18000: Train Loss 0.0767, Val Loss 0.0766\n",
      "Iter 19000: Train Loss 0.0742, Val Loss 0.0741\n",
      "Iter 20000: Train Loss 0.0719, Val Loss 0.0718\n",
      "Iter 21000: Train Loss 0.0698, Val Loss 0.0697\n",
      "Iter 22000: Train Loss 0.0678, Val Loss 0.0677\n",
      "Iter 23000: Train Loss 0.0660, Val Loss 0.0659\n",
      "Iter 24000: Train Loss 0.0644, Val Loss 0.0642\n",
      "Iter 25000: Train Loss 0.0628, Val Loss 0.0627\n",
      "Iter 26000: Train Loss 0.0614, Val Loss 0.0612\n",
      "Iter 27000: Train Loss 0.0600, Val Loss 0.0598\n",
      "Iter 28000: Train Loss 0.0587, Val Loss 0.0586\n",
      "Iter 29000: Train Loss 0.0576, Val Loss 0.0574\n",
      "Iter 30000: Train Loss 0.0564, Val Loss 0.0562\n",
      "Iter 31000: Train Loss 0.0554, Val Loss 0.0551\n",
      "Iter 32000: Train Loss 0.0544, Val Loss 0.0541\n",
      "Iter 33000: Train Loss 0.0534, Val Loss 0.0532\n",
      "Iter 34000: Train Loss 0.0525, Val Loss 0.0522\n",
      "Iter 35000: Train Loss 0.0517, Val Loss 0.0514\n",
      "Iter 36000: Train Loss 0.0508, Val Loss 0.0505\n",
      "Iter 37000: Train Loss 0.0501, Val Loss 0.0498\n",
      "Iter 38000: Train Loss 0.0493, Val Loss 0.0490\n",
      "Iter 39000: Train Loss 0.0486, Val Loss 0.0483\n",
      "Iter 40000: Train Loss 0.0479, Val Loss 0.0476\n",
      "Iter 41000: Train Loss 0.0473, Val Loss 0.0469\n",
      "Iter 42000: Train Loss 0.0467, Val Loss 0.0463\n",
      "Iter 43000: Train Loss 0.0461, Val Loss 0.0457\n",
      "Iter 44000: Train Loss 0.0455, Val Loss 0.0451\n",
      "Iter 45000: Train Loss 0.0449, Val Loss 0.0445\n",
      "Iter 46000: Train Loss 0.0444, Val Loss 0.0440\n",
      "Iter 47000: Train Loss 0.0439, Val Loss 0.0434\n",
      "Iter 48000: Train Loss 0.0434, Val Loss 0.0429\n",
      "Iter 49000: Train Loss 0.0429, Val Loss 0.0424\n",
      "Test Accuracy: 93.69%\n"
     ]
    }
   ],
   "execution_count": 82
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

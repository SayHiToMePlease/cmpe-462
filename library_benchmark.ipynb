{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67633784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e55ff9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully:\n",
      "Train shape: (2791, 106), Test shape: (301, 106)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. Data Loading & Preparation\n",
    "# ==========================================\n",
    "\n",
    "def load_data(filename):\n",
    "    path = os.path.join(\"data\", \"tabular\", filename)\n",
    "    data = pl.read_csv(path).to_numpy()\n",
    "    X = data[:, :-1].astype(float)\n",
    "    y = data[:, -1]\n",
    "    return X, y\n",
    "\n",
    "try:\n",
    "    X_train, y_train = load_data(\"train_processed.csv\")\n",
    "    # X_val, y_val = load_data(\"validation_processed.csv\")\n",
    "    X_test, y_test = load_data(\"test_processed.csv\")\n",
    "    print(f\"Data loaded successfully:\\nTrain shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV for train and/or test not found! Please ensure their existence in this universe!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "692477fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. Configuration: Models & Hyperparameters\n",
    "# ==========================================\n",
    "\n",
    "configs = {\n",
    "    # 1. Logistic Regression\n",
    "    'Logistic Regression': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()), \n",
    "            ('clf', LogisticRegression(max_iter=2000))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__C': [0.1, 1, 10], \n",
    "            'clf__solver': ['lbfgs', 'liblinear']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # 2. Logistic Regression + Non-Linear Transformation\n",
    "    'Log. Reg. (Non-Linear)': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('poly', PolynomialFeatures(degree=2)), # The non-linear transform\n",
    "            ('clf', LogisticRegression(max_iter=2000))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__C': [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # 3. Soft-margin SVM (Linear)\n",
    "    'SVM (Linear)': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clf', SVC(kernel='linear', max_iter=10000))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__C': [0.1, 1, 10] # Controls soft-margin strictness\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # 4. Soft-margin SVM (Kernel Trick)\n",
    "    'SVM (Kernel RBF)': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clf', SVC(kernel='rbf', max_iter=10000))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__C': [0.1, 1, 10],\n",
    "            'clf__gamma': ['scale', 'auto']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # 5. k-Nearest Neighbors\n",
    "    'k-NN': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clf', KNeighborsClassifier())\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__n_neighbors': [3, 5, 7, 9],\n",
    "            'clf__weights': ['uniform', 'distance']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # 6. Naive Bayes\n",
    "    'Naive Bayes': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()), # Optional for NB, but often helps\n",
    "            ('clf', GaussianNB())\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__var_smoothing': [1e-9, 1e-8]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # 7. Random Forest\n",
    "    'Random Forest': {\n",
    "        'pipeline': Pipeline([\n",
    "            # Scaling is not strictly necessary for RF, but doesn't hurt in pipeline\n",
    "            ('clf', RandomForestClassifier(random_state=42))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'clf__n_estimators': [50, 100],\n",
    "            'clf__max_depth': [None, 10, 20]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a250e2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Benchmark\n",
      "==================================================\n",
      "Training Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saura\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log. Reg. (Non-Linear)\n",
      "Training SVM (Linear)\n",
      "Training SVM (Kernel RBF)\n",
      "Training k-NN\n",
      "Training Naive Bayes\n",
      "Training Random Forest\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. Training & Benchmarking Loop\n",
    "# ==========================================\n",
    "\n",
    "results_data = []\n",
    "\n",
    "print(\"Start Benchmark\\n\" + \"=\"*50)\n",
    "\n",
    "for name, config in configs.items():\n",
    "    print(f\"Training {name}\")\n",
    "\n",
    "    # Initialize GridSearch\n",
    "    grid = GridSearchCV(\n",
    "            config['pipeline'], \n",
    "            config['params'], \n",
    "            cv=5, \n",
    "            n_jobs=-1, # Use all CPU cores\n",
    "            scoring='accuracy'\n",
    "        )\n",
    "    \n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    grid.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Get best model from GridSearch\n",
    "    best_model = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "\n",
    "    # Evaluate on Test Set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Store results\n",
    "    results_data.append({\n",
    "        'Classifier': name,\n",
    "        'Best Hyperparameters': str(best_params),\n",
    "        'Training Time (sec)': round(training_time, 4),\n",
    "        'Test Accuracy': round(acc, 4)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7caa4a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "FINAL BENCHMARKING RESULTS\n",
      "========================================\n",
      "               Classifier                               Best Hyperparameters  \\\n",
      "0     Logistic Regression          {'clf__C': 1, 'clf__solver': 'liblinear'}   \n",
      "1  Log. Reg. (Non-Linear)                                    {'clf__C': 0.1}   \n",
      "2            SVM (Linear)                                    {'clf__C': 0.1}   \n",
      "3        SVM (Kernel RBF)               {'clf__C': 1, 'clf__gamma': 'scale'}   \n",
      "4                    k-NN  {'clf__n_neighbors': 9, 'clf__weights': 'dista...   \n",
      "5             Naive Bayes                      {'clf__var_smoothing': 1e-08}   \n",
      "6           Random Forest   {'clf__max_depth': 20, 'clf__n_estimators': 100}   \n",
      "\n",
      "   Training Time (sec)  Test Accuracy  \n",
      "0               8.0565         0.9003  \n",
      "1               9.5813         0.7708  \n",
      "2               0.5366         0.9103  \n",
      "3               1.6303         0.8405  \n",
      "4               0.6283         0.6146  \n",
      "5               0.2184         0.8571  \n",
      "6               5.7214         0.7342  \n",
      "\n",
      "Results saved to 'benchmark_results_task1.csv'.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. Reporting\n",
    "# ==========================================\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"FINAL BENCHMARKING RESULTS\")\n",
    "print(\"=\"*40)\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('benchmark_results_task1.csv', index=False)\n",
    "print(\"\\nResults saved to 'benchmark_results_task1.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

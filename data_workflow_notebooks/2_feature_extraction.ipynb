{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d1d7e68fcd0259d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T16:33:39.920126053Z",
     "start_time": "2026-01-03T16:33:39.901189476Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "# import polars as pl  # didn't use pl because i didn't know how to use it when normalizing\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe86664a598b6a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T16:33:39.972871704Z",
     "start_time": "2026-01-03T16:33:39.922384771Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 462\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "DESCRIPTION_WORDS_COUNT = 3\n",
    "GRAYSCALE_SIZE = (8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e5e5c92672ee99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T16:33:40.041288697Z",
     "start_time": "2026-01-03T16:33:39.974737931Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "image_data_path = os.path.join(data_path, \"image\")\n",
    "vocabulary_path = os.path.join(data_path, \"vocabulary.json\")\n",
    "# dataset_splits = [\"train\", \"validation\", \"test\"]\n",
    "dataset_splits = [\"train\", \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c9b05b231f6161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T16:33:40.089774326Z",
     "start_time": "2026-01-03T16:33:40.080356306Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATURES = {\"image\": True, \"numeric\": False, \"text\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194462675308a558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T16:33:40.141828579Z",
     "start_time": "2026-01-03T16:33:40.092080728Z"
    }
   },
   "outputs": [],
   "source": [
    "def enumerate_dataset(dataset_path):\n",
    "    return {cls: os.listdir(os.path.join(dataset_path, cls)) for cls in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, cls))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "585df0f4cef59e36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T16:33:40.194304296Z",
     "start_time": "2026-01-03T16:33:40.143775628Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = {dataset: enumerate_dataset(os.path.join(image_data_path, dataset)) for dataset in dataset_splits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6edde39c4eb76928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T16:33:40.253987351Z",
     "start_time": "2026-01-03T16:33:40.196064923Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_words = {\n",
    "    \"banana\": [\n",
    "        \"tropical\", \"long\", \"sweet\", \"soft\", \"peel\",\n",
    "        \"fruit\", \"fresh\", \"yellow\", \"curved\", \"food\",\n",
    "        \"healthy\", \"vitamin\", \"market\", \"tasty\", \"snack\"\n",
    "    ],\n",
    "    \"carrot\": [\n",
    "        \"temperate\", \"long\", \"sweet\", \"crunchy\", \"skin\",\n",
    "        \"vegetable\", \"fresh\", \"orange\", \"root\", \"food\",\n",
    "        \"healthy\", \"vitamin\", \"market\", \"tasty\", \"salad\"\n",
    "    ],\n",
    "    \"cucumber\": [\n",
    "        \"temperate\", \"long\", \"bland\", \"crunchy\", \"seeds\",\n",
    "        \"vegetable\", \"fresh\", \"green\", \"water\", \"food\",\n",
    "        \"healthy\", \"vitamin\", \"market\", \"salad\", \"skin\"\n",
    "    ],\n",
    "    \"mandarin\": [\n",
    "        \"tropical\", \"spherical\", \"sweet\", \"sour\", \"soft\", \"peel\",\n",
    "        \"fruit\", \"fresh\", \"orange\", \"citrus\", \"food\",\n",
    "        \"healthy\", \"vitamin\", \"market\", \"tasty\", \"snack\"\n",
    "    ],\n",
    "    \"tomato\": [\n",
    "        \"warm\", \"spherical\", \"savory\", \"sour\", \"soft\", \"seeds\",\n",
    "        \"vegetable\", \"fresh\", \"red\", \"juice\", \"food\",\n",
    "        \"healthy\", \"vitamin\", \"market\", \"salad\", \"sauce\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf9eb068c088f268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T16:33:40.308448496Z",
     "start_time": "2026-01-03T16:33:40.255952240Z"
    }
   },
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "for words in feature_words.values():\n",
    "    for word in words:\n",
    "        vocabulary.add(word)\n",
    "vocabulary = sorted(vocabulary)\n",
    "with open(vocabulary_path, \"w\") as fp:\n",
    "    json.dump(vocabulary, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa9ef977bafcf63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T16:33:40.363808431Z",
     "start_time": "2026-01-03T16:33:40.312249720Z"
    }
   },
   "outputs": [],
   "source": [
    "# grams(mean, std), cm(mean, std)\n",
    "dist_params = {\n",
    "    \"banana\": {\"weight\": (160, 30), \"size\": (18, 5)},\n",
    "    \"carrot\": {\"weight\": (75, 20), \"size\": (17, 4)},\n",
    "    \"cucumber\": {\"weight\": (140, 55), \"size\": (20, 6)},\n",
    "    \"mandarin\": {\"weight\": (85, 12), \"size\": (6, 1.5)},\n",
    "    \"tomato\": {\"weight\": (95, 20), \"size\": (6.5, 1.5)},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "369bafddda79c3cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T16:33:40.424311239Z",
     "start_time": "2026-01-03T16:33:40.365683361Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(image, image_class):\n",
    "    features = {}\n",
    "\n",
    "    if FEATURES[\"image\"]:\n",
    "        small = cv2.resize(image, GRAYSCALE_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        gray_small = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)\n",
    "        gray_flat = gray_small.reshape(-1).astype(\"float32\")\n",
    "        for i, val in enumerate(gray_flat):\n",
    "            features[f\"gray_{i:03d}\"] = float(val)  # type: ignore | here we know gray_flat is 1d array\n",
    "\n",
    "        blue = image[:, :, 0]\n",
    "        green = image[:, :, 1]\n",
    "        red = image[:, :, 2]\n",
    "\n",
    "        features[\"blue_mean\"] = float(np.mean(blue))\n",
    "        features[\"blue_std\"] = float(np.std(blue))\n",
    "        features[\"green_mean\"] = float(np.mean(green))\n",
    "        features[\"green_std\"] = float(np.std(green))\n",
    "        features[\"red_mean\"] = float(np.mean(red))\n",
    "        features[\"red_std\"] = float(np.std(red))\n",
    "\n",
    "    if FEATURES[\"numeric\"]:\n",
    "        params = dist_params[image_class]\n",
    "        features[\"weight\"] = float(np.random.normal(*params[\"weight\"]))\n",
    "        features[\"size\"] = float(np.random.normal(*params[\"size\"]))\n",
    "\n",
    "    if FEATURES[\"text\"]:\n",
    "        features[\"description\"] = \" \".join(random.sample(feature_words[image_class], DESCRIPTION_WORDS_COUNT))\n",
    "\n",
    "    features[\"class\"] = image_class\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7a3399b05f435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T16:35:04.904024197Z",
     "start_time": "2026-01-03T16:33:40.425867555Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[32m      9\u001b[39m     image_path = os.path.join(image_data_path, split, class_, image)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     features = extract_features(\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m, class_)\n\u001b[32m     11\u001b[39m     features[\u001b[33m\"\u001b[39m\u001b[33mfile_name\u001b[39m\u001b[33m\"\u001b[39m] = image_path\n\u001b[32m     12\u001b[39m     rows.append(features)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "tabular_path = os.path.join(data_path, \"tabular\")\n",
    "os.makedirs(tabular_path, exist_ok=True)\n",
    "normalized_cols = [f\"gray_{i:03d}\" for i in range(GRAYSCALE_SIZE[0] ** 2)] + [\"blue_mean\", \"blue_std\", \"green_mean\", \"green_std\", \"red_mean\", \"red_std\"]\n",
    "for split, dataset in datasets.items():\n",
    "    destination_path = os.path.join(tabular_path, f\"{split}_img_only.csv\")\n",
    "    rows = []\n",
    "    for class_, images in dataset.items():\n",
    "        for image in images:\n",
    "            image_path = os.path.join(image_data_path, split, class_, image)\n",
    "            features = extract_features(cv2.imread(image_path), class_)\n",
    "            features[\"file_name\"] = image_path\n",
    "            rows.append(features)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sample(frac=1, random_state=SEED).reset_index(drop=True)  # to shuffle df rows\n",
    "    df.to_csv(destination_path, index=False)\n",
    "\n",
    "\"\"\"\n",
    "we need to apply normalization based on the values calculated from\n",
    "the training set since they are the values that are learned by the \n",
    "model\n",
    "\"\"\"\n",
    "train_df = pd.read_csv(os.path.join(tabular_path, \"train_img_only.csv\"))\n",
    "mean     = train_df[normalized_cols].mean()\n",
    "std      = train_df[normalized_cols].std()\n",
    "\n",
    "for split in dataset_splits:\n",
    "    df = pd.read_csv(os.path.join(tabular_path, f\"{split}_img_only.csv\"))\n",
    "    df[normalized_cols] = (df[normalized_cols] - mean) / std\n",
    "    df.to_csv(os.path.join(tabular_path, f\"{split}.csv\"), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

\documentclass[11pt, a4paper]{article}

% --- 1. Page Layout & Formatting ---
\usepackage{geometry}
\geometry{
    top=25mm,
    bottom=25mm,
    left=25mm,
    right=25mm
}
\usepackage{parskip}  % Adds space between paragraphs (modern look)
\usepackage{setspace} % For line spacing
\onehalfspacing       % 1.5 line spacing (easier to read)

% --- 2. Fonts ---
\usepackage{mathpazo} % Uses Palatino font
\usepackage[T1]{fontenc}

% --- 3. Graphics & Tables ---
\usepackage{graphicx}
\usepackage{float}
\usepackage{booktabs}
\usepackage{caption}

% --- 4. Links & Metadata ---
\usepackage[hidelinks]{hyperref}
\usepackage{url} % <--- ADDED: To display website URLs correctly

\usepackage{multirow}

% --- 5. Title Section ---
\title{\textbf{CMPE 462 - Machine Learning: Assignment 1}}
\author{Asaf Kanlipicak, Ali Sonmez, Saur}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}
This report outlines our work on developing a multi-class classification model for fruit and vegetables. For the project, we needed to create a custom dataset consisting of five distinct classes: banana, carrot, cucumber, mandarin, and tomato. Two primary goals of the project was to understand the mechanics of classification algorithms by building one from scratch and facing with the difficulties of data collection.

In the following sections, we describe how we collected and processed our data (combining images, text, and numerical attributes), detail our custom implementation, and compare its performance against the standard Scikit-learn library.

\section{Dataset}
\subsection*{Examples}

Our dataset includes \textbf{5922} images in total. We have \textbf{301} real photographs and \textbf{5621} generated images.

\begin{table}[h]
    \centering
    \caption{Distribution of Generated and Photograph Images per Class}
    \vspace{0.2cm}
    \begin{tabular}{lrrr}
        \toprule
        \textbf{Class} & \textbf{Generated} & \textbf{Photograph} & \textbf{Total} \\
        \midrule
        Banana   & 1000 & 100 & 1100 \\
        Carrot   & 1173 & 50  & 1223 \\
        Cucumber & 1000 & 50  & 1050 \\
        Mandarin & 1000 & 51  & 1051 \\
        Tomato   & 1448 & 50  & 1498 \\
        \midrule
        \textbf{Total} & \textbf{5621} & \textbf{301} & \textbf{5922} \\
        \bottomrule
    \end{tabular}
    \label{tab:dataset_dist}
\end{table}

We have separated 0.8 of the generated images as our \textbf{training} set and 0.2 of it as our \textbf{validation} set.
To see if a model which is trained on generated images can predict real photographs, we have selected all the photographs as our \textbf{test} set.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{figures/gen_ban.png} 
    \caption{A generated banana}
    \label{fig:example}
\end{figure}

\begin{table}[h]
    \centering
    \caption{Example Feature Vector (Class: Banana)}
    \vspace{0.2cm}
    \begin{tabular}{llp{6cm}}
        \toprule
        \textbf{Feature Group} & \textbf{Attributes} & \textbf{Values} \\
        \midrule
        \multirow{2}{*}{Grayscale Histogram} & gray\_000 \dots gray\_005 & 2.0, 2.0, 13.0, 76.0, 77.0, 51.0 \dots \\
                                             & \dots gray\_063 & \dots 205.0 \\
        \midrule
        \multirow{3}{*}{Color Statistics}    & blue\_mean, blue\_std & 73.93, 67.23 \\
                                             & green\_mean, green\_std & 133.87, 84.41 \\
                                             & red\_mean, red\_std & 163.57, 100.53 \\
        \midrule
        Physical Attributes                  & weight, size & 130.93 g, 17.86 cm \\
        \midrule
        Text Description                     & description & "soft yellow" \\
        \midrule
        \textbf{Target Label}                & \textbf{class} & \textbf{banana} \\
        \bottomrule
    \end{tabular}
    \label{tab:feature_example}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{figures/gen_car.png} 
    \caption{A generated carrot}
    \label{fig:example}
\end{figure}

\begin{table}[h]
    \centering
    \caption{Example Feature Vector (Class: Carrot)}
    \vspace{0.2cm}
    \begin{tabular}{llp{6cm}}
        \toprule
        \textbf{Feature Group} & \textbf{Attributes} & \textbf{Values} \\
        \midrule
        \multirow{2}{*}{Grayscale Histogram} & gray\_000 \dots gray\_005 & 221.0, 217.0, 208.0, 193.0, 206.0, 202.0 \dots \\
                                             & \dots gray\_063 & \dots 172.0 \\
        \midrule
        \multirow{3}{*}{Color Statistics}    & blue\_mean, blue\_std & 172.12, 57.35 \\
                                             & green\_mean, green\_std & 178.13, 48.76 \\
                                             & red\_mean, red\_std & 190.24, 35.87 \\
        \midrule
        Physical Attributes                  & weight, size & 46.06 g, 11.84 cm \\
        \midrule
        Text Description                     & description & "orange temperate" \\
        \midrule
        \textbf{Target Label}                & \textbf{class} & \textbf{carrot} \\
        \bottomrule
    \end{tabular}
    \label{tab:feature_example_carrot}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{figures/gen_cuc.png} 
    \caption{A generated cucumber}
    \label{fig:example}
\end{figure}

\begin{table}[h]
    \centering
    \caption{Example Feature Vector (Class: Cucumber)}
    \vspace{0.2cm}
    \begin{tabular}{llp{6cm}}
        \toprule
        \textbf{Feature Group} & \textbf{Attributes} & \textbf{Values} \\
        \midrule
        \multirow{2}{*}{Grayscale Histogram} & gray\_000 \dots gray\_005 & 175.0, 168.0, 163.0, 159.0, 160.0, 154.0 \dots \\
                                             & \dots gray\_063 & \dots 190.0 \\
        \midrule
        \multirow{3}{*}{Color Statistics}    & blue\_mean, blue\_std & 149.94, 82.32 \\
                                             & green\_mean, green\_std & 173.52, 66.73 \\
                                             & red\_mean, red\_std & 175.36, 70.31 \\
        \midrule
        Physical Attributes                  & weight, size & 287.30 g, 25.95 cm \\
        \midrule
        Text Description                     & description & "temperate long" \\
        \midrule
        \textbf{Target Label}                & \textbf{class} & \textbf{cucumber} \\
        \bottomrule
    \end{tabular}
    \label{tab:feature_example_cucumber}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{figures/gen_man.png} 
    \caption{A generated mandarin}
    \label{fig:example}
\end{figure}

\begin{table}[h]
    \centering
    \caption{Example Feature Vector (Class: Mandarin)}
    \vspace{0.2cm}
    \begin{tabular}{llp{6cm}}
        \toprule
        \textbf{Feature Group} & \textbf{Attributes} & \textbf{Values} \\
        \midrule
        \multirow{2}{*}{Grayscale Histogram} & gray\_000 \dots gray\_005 & 186.0, 204.0, 225.0, 234.0, 230.0, 200.0 \dots \\
                                             & \dots gray\_063 & \dots 110.0 \\
        \midrule
        \multirow{3}{*}{Color Statistics}    & blue\_mean, blue\_std & 164.11, 85.86 \\
                                             & green\_mean, green\_std & 190.25, 53.10 \\
                                             & red\_mean, red\_std & 212.07, 44.73 \\
        \midrule
        Physical Attributes                  & weight, size & 76.19 g, 7.87 cm \\
        \midrule
        Text Description                     & description & "sour soft" \\
        \midrule
        \textbf{Target Label}                & \textbf{class} & \textbf{mandarin} \\
        \bottomrule
    \end{tabular}
    \label{tab:feature_example_mandarin}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{figures/gen_tom.png} 
    \caption{A generated tomato}
    \label{fig:example}
\end{figure}

\begin{table}[h]
    \centering
    \caption{Example Feature Vector (Class: Tomato)}
    \vspace{0.2cm}
    \begin{tabular}{llp{6cm}}
        \toprule
        \textbf{Feature Group} & \textbf{Attributes} & \textbf{Values} \\
        \midrule
        \multirow{2}{*}{Grayscale Histogram} & gray\_000 \dots gray\_005 & 135.0, 144.0, 122.0, 147.0, 218.0, 159.0 \dots \\
                                             & \dots gray\_063 & \dots 50.0 \\
        \midrule
        \multirow{3}{*}{Color Statistics}    & blue\_mean, blue\_std & 100.99, 72.33 \\
                                             & green\_mean, green\_std & 112.19, 72.33 \\
                                             & red\_mean, red\_std & 130.97, 63.93 \\
        \midrule
        Physical Attributes                  & weight, size & 108.11 g, 4.12 cm \\
        \midrule
        Text Description                     & description & "soft sour" \\
        \midrule
        \textbf{Target Label}                & \textbf{class} & \textbf{tomato} \\
        \bottomrule
    \end{tabular}
    \label{tab:feature_example_tomato}
\end{table}

\subsection*{Data Collection}
To obtain a large dataset we employed two techniques:

\begin{itemize}
    \item \textbf{Generation:} The majority of the data was generated using \textbf{Stability AI's Stable Diffusion 3.5 Medium} model. Our prompts are visible in the generation notebook.
    \item \textbf{Manual Photography:} Additionally, we manually took photographs of the actual fruits and vegetables. These are used as the test set.
\end{itemize}

\subsection*{Preprocessing Pipeline}
We wrote a preprocessing script (\texttt{image\_processing.ipynb}) to standardize the raw inputs before feature extraction. Our pipeline is:

\begin{enumerate}
    \item \textbf{Resizing:} All images, regardless of their original resolution, are resized to a uniform dimension of \textbf{$512 \times 512$ pixels}.
    \item \textbf{Randomization:} A fixed seed (\texttt{SEED = 462}) was used to shuffle the dataset for reproducability concerns.
\end{enumerate}

\subsection*{Dataset Splitting Strategy}
We separated the data as follows:

\begin{itemize}
    \item \textbf{Training \& Validation Sets:} Derived from the \textbf{generated} images. The generated data was shuffled and split with an \textbf{80/20 ratio}:
    \begin{itemize}
        \item \textbf{80\%} allocated to the Training set.
        \item \textbf{20\%} allocated to the Validation set.
    \end{itemize}
    \item \textbf{Test Set:} Composed only of the \textbf{real-world photographs}.
\end{itemize}

With the help of this splitting, we can test an interesting case in which a model is trained using generated images, but tested on the real ones.


\subsection*{Future Extraction}
We have \textbf{72} features in total, 64 of which is the grayscale representation of the image. The other 8 is related to colors, physical attributes, and semantic information.

\subsubsection*{Grayscale Histogram (8 $\times$ 8 = 64 features)}
We convert each image into a 8$\times$8 grayscale image and give the value of each pixel as a feature to our model. This helps distinguishing between objects with similar colors but different surface textures (e.g., the smooth surface of a tomato vs. the rougher texture of a carrot).

\textbf{How did we extract:} We made use of OpenCV to convert the image into grayscale and resize it to 8$\times$8.

\subsubsection*{Color Statistics (RGB Mean and Standard Deviation)}
Color is the most intuitive discriminator for this specific dataset.
\begin{itemize}
    \item \textbf{Mean:} Captures the dominant color of the object. This is crucial to separate the objects with different colors such as banana and mandarin.
    \item \textbf{Standard Deviation:} Captures the color variance. Even though we are not sure, we think that standard deviation might help the model learn some texture specific relation. (On the surface of a cucumber, there might be frequent dark spots.)
\end{itemize}
\textbf{How did we extract:} We made use of OpenCV to read the color value of each pixel in an image. Afterwards, it was just simple math to calculate the features.

\subsubsection*{Physical Attributes (Weight and Size)}
Weight and size are important features since these help the model to learn, hopefully, the geometric attributes of an object. 
\begin{itemize}
    \item These features define the geometric and physical boundaries of the classes (A cucumber is significantly longer/larger than a mandarin).
\end{itemize}
\textbf{How did we extract:} This might be the trickiest one to extract. We used Gaussian distributions with different mean and variance values for each class to generate weights and sizes. For example, the average weight of a banana is 120 g, with a variance of 16 gÂ² in the code. These values were derived by asking to ChatGPT since there are multiple answers on the Internet, but we want one.

\subsubsection*{Semantic Features (Text Description)}
We have selected a set of words to define different classes. However, we paid attention not to make them easily separable. For example, if an object can have the word ``tropical'' in its text feature, then, another one also can.
\begin{itemize}
    \item We aim to make the model learn the relation between a \textit{bag of words} and a class. With combination of words, it is feasible to separate the objects that share some common words.
\end{itemize}
\textbf{How did we extract:} We created a vocabulary in which we aggregated all unique descriptors (e.g., colors, textures, origins) across all classes. We then represented the text description of each sample as a binary feature vector, where each dimension corresponds to the presence (1) or absence (0) of a specific word from this vocabulary. This resulted in a representation whcih encodes the attributes defined in our vocabulary.

\end{document}